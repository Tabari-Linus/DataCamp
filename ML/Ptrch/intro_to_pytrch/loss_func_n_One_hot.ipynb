{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.nn import CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-hot vector using NumPy: [0 1 0]\n",
      "One-hot vector using PyTorch: tensor([0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "y = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Create the one-hot encoded vector using NumPy\n",
    "one_hot_numpy = np.array([0, y, 0])\n",
    "\n",
    "# Create the one-hot encoded vector using PyTorch\n",
    "one_hot_pytorch = F.one_hot(torch.tensor(y), num_classes=num_classes)\n",
    "\n",
    "print(\"One-hot vector using NumPy:\", one_hot_numpy)\n",
    "print(\"One-hot vector using PyTorch:\", one_hot_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function \n",
    "* Cross Entropyloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.0619, dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "y = [2]\n",
    "scores = torch.tensor([[0.1, 6.0, -2.0, 3.2]])\n",
    "\n",
    "# Create a one-hot encoded vector of the label y\n",
    "one_hot_label = F.one_hot(torch.tensor(y), num_classes=4)\n",
    "\n",
    "# Create the cross entropy loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Calculate the cross entropy loss\n",
    "loss = criterion(scores.double(), one_hot_label.double())\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight of the first layer: Parameter containing:\n",
      "tensor([[ 0.0344, -0.0113, -0.1036,  0.1958,  0.0990, -0.2055, -0.1388, -0.0924,\n",
      "         -0.0313, -0.0986,  0.0682, -0.1275,  0.0561,  0.0565, -0.0414,  0.0261],\n",
      "        [-0.0022,  0.0739, -0.1619, -0.1332,  0.0906,  0.1816, -0.1493,  0.0844,\n",
      "         -0.0980, -0.0441,  0.2383, -0.1445,  0.0373,  0.1124, -0.1386,  0.0992],\n",
      "        [-0.0529,  0.0354, -0.2214,  0.0090, -0.1230, -0.1756,  0.1414, -0.2457,\n",
      "         -0.0685,  0.1354,  0.2193,  0.1125,  0.1278, -0.0660,  0.1550,  0.0781],\n",
      "        [-0.0722,  0.0240,  0.0774, -0.1045, -0.0280,  0.0463,  0.0004, -0.0887,\n",
      "          0.1312,  0.0439,  0.1330, -0.0211, -0.2249, -0.2417, -0.0148, -0.0976],\n",
      "        [ 0.2009,  0.0189, -0.2390,  0.1494,  0.0270, -0.0015, -0.1350, -0.1424,\n",
      "         -0.0114, -0.0881, -0.2076, -0.1124,  0.1236, -0.0641,  0.1213, -0.1800],\n",
      "        [ 0.1899, -0.0610,  0.2383,  0.2032,  0.0422,  0.0411,  0.1490, -0.1361,\n",
      "         -0.1209, -0.0172,  0.1026, -0.2436, -0.0872,  0.0853,  0.0771, -0.1332],\n",
      "        [ 0.0008, -0.0835,  0.1265,  0.0786, -0.1399, -0.0068, -0.0237, -0.0572,\n",
      "          0.1836, -0.1142, -0.0813, -0.1733, -0.0213, -0.1210, -0.1898, -0.0975],\n",
      "        [-0.0721, -0.0446,  0.0187, -0.0156, -0.1733,  0.1446,  0.0811, -0.2164,\n",
      "         -0.1861,  0.0005, -0.0406, -0.1816,  0.1134,  0.0928,  0.0143, -0.1402]],\n",
      "       requires_grad=True)\n",
      "Bias of the second layer: Parameter containing:\n",
      "tensor([0.1398, 0.0512], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(16, 8),\n",
    "                      nn.Linear(8, 2)\n",
    "                     )\n",
    "\n",
    "# Access the weight of the first linear layer\n",
    "weight_0 = model[0].weight\n",
    "print(\"Weight of the first layer:\", weight_0)\n",
    "\n",
    "# Access the bias of the second linear layer\n",
    "bias_1 = model[1].bias\n",
    "print(\"Bias of the second layer:\", bias_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating weights manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight0 = model[0].weight\n",
    "# weight1 = model[1].weight\n",
    "# lr = 0.001\n",
    "\n",
    "# # Access the gradients of the weight of each linear layer\n",
    "# grads0 = weight0.grad\n",
    "# grads1 = weight1.grad\n",
    "\n",
    "\n",
    "# # Update the weights using the learning rate and the gradients\n",
    "# weight0 = weight0 - lr*grads0\n",
    "# weight1 = weight1 -lr*grads1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Updating with optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create the optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# loss = criterion(pred, target)\n",
    "# loss.backward()\n",
    "\n",
    "# # Update the model's parameters using the optimizer\n",
    "# optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
